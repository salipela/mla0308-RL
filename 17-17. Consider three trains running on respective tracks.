import numpy as np

class Train:
    def __init__(self, algorithm):
        self.algorithm = algorithm
        self.Q = np.zeros((5, 2)) 
        self.alpha = 0.1  
        self.gamma = 0.9 
        self.state = 0 
        self.steps = 0  
    def choose_action(self):
       
        return np.random.randint(2)

    def take_action(self, action):
     
        if self.state == 4 and action == 1: 
            reward = 1
            next_state = None
        else:
            reward = 0
            next_state = self.state + 1 if action == 1 else self.state

        return reward, next_state

    def update_policy(self, reward, next_state, next_action):
        if self.algorithm == "TD(0)":

            if next_state is not None:
                td_target = reward + self.gamma * self.Q[next_state, next_action]
            else:
                td_target = reward
            td_error = td_target - self.Q[self.state, next_action]
            self.Q[self.state, next_action] += self.alpha * td_error
        elif self.algorithm == "SARSA":
          
            if next_state is not None:
                td_target = reward + self.gamma * self.Q[next_state, next_action]
            else:
                td_target = reward
            td_error = td_target - self.Q[self.state, next_action]
            self.Q[self.state, next_action] += self.alpha * td_error
        elif self.algorithm == "Q-learning":
       
            if next_state is not None:
                td_target = reward + self.gamma * np.max(self.Q[next_state])
            else:
                td_target = reward
            td_error = td_target - self.Q[self.state, next_action]
            self.Q[self.state, next_action] += self.alpha * td_error

    def train(self, num_episodes):
        for _ in range(num_episodes):
            self.state = 0
            while self.state is not None:
                action = self.choose_action()
                reward, next_state = self.take_action(action)
                next_action = self.choose_action() if next_state is not None else None
                self.update_policy(reward, next_state, next_action)
                self.state = next_state
                self.steps += 1


def evaluate_performance(algorithm, num_episodes=1000):
    train = Train(algorithm)
    train.train(num_episodes)
    return train.steps


steps_TD = evaluate_performance("TD(0)")
steps_SARSA = evaluate_performance("SARSA")
steps_Q_learning = evaluate_performance("Q-learning")

print("Steps taken for TD(0):", steps_TD)
print("Steps taken for SARSA:", steps_SARSA)
print("Steps taken for Q-learning:", steps_Q_learning)

if steps_TD < steps_SARSA and steps_TD < steps_Q_learning:
    print("TD(0) performs better.")
elif steps_SARSA < steps_TD and steps_SARSA < steps_Q_learning:
    print("SARSA performs better.")
else:
    print("Q-learning performs better.")
